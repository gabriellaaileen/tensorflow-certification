{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question4_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriellaaileen/tensorflow-certification/blob/main/Question4_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Tit-wZGOvhYI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oYciaUFIx64x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533b3319-54c2-448f-bf52-76c2ad386a08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "data = open('/content/drive/MyDrive/poem.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)\n",
        "\n",
        "print(max_sequence_len)"
      ],
      "metadata": {
        "id": "gMRo6fwovkVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e35c43b-5471-4f3e-f693-9a4209fd9c34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ULFEKhOZm-0",
        "outputId": "37545441-dc4a-4f7e-935f-4883660bcb58"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#buatlah model dengan output layer total words/2 dan total word\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu')),\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu')),\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu')),\n",
        "model.add(tf.keras.layers.Dropout(0.2)),\n",
        "model.add(tf.keras.layers.Dense(total_words, activation='softmax'))"
      ],
      "metadata": {
        "id": "D0dSWWg7vmW5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB7MGGdDcTov",
        "outputId": "7061fc83-0abf-4f74-82e0-93a9449eed6c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 15, 100)           380800    \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 128)              84480     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 3808)              978656    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,493,536\n",
            "Trainable params: 1,493,536\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gunakan loss categorical_crossentropy\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "4Pz9dFi5vo78"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training model \n",
        "history = model.fit(\n",
        "    predictors,label,batch_size=128,epochs=400,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "cMCMd8U5ypod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb19bf98-8425-45b1-e786-d8b8b0a85d98"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "102/102 [==============================] - 16s 120ms/step - loss: 7.0928 - accuracy: 0.0604 - val_loss: 7.0804 - val_accuracy: 0.0616\n",
            "Epoch 2/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 6.5769 - accuracy: 0.0632 - val_loss: 7.2413 - val_accuracy: 0.0616\n",
            "Epoch 3/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 6.4407 - accuracy: 0.0632 - val_loss: 7.4040 - val_accuracy: 0.0616\n",
            "Epoch 4/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 6.3440 - accuracy: 0.0635 - val_loss: 7.3591 - val_accuracy: 0.0631\n",
            "Epoch 5/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 6.1965 - accuracy: 0.0650 - val_loss: 7.4104 - val_accuracy: 0.0634\n",
            "Epoch 6/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 6.0697 - accuracy: 0.0672 - val_loss: 7.6398 - val_accuracy: 0.0644\n",
            "Epoch 7/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 5.9536 - accuracy: 0.0731 - val_loss: 7.7521 - val_accuracy: 0.0662\n",
            "Epoch 8/400\n",
            "102/102 [==============================] - 11s 104ms/step - loss: 5.8213 - accuracy: 0.0779 - val_loss: 7.9367 - val_accuracy: 0.0677\n",
            "Epoch 9/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 5.6993 - accuracy: 0.0886 - val_loss: 7.9652 - val_accuracy: 0.0677\n",
            "Epoch 10/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 5.5927 - accuracy: 0.0924 - val_loss: 8.2462 - val_accuracy: 0.0650\n",
            "Epoch 11/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 5.4814 - accuracy: 0.0991 - val_loss: 8.4551 - val_accuracy: 0.0647\n",
            "Epoch 12/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 5.3781 - accuracy: 0.1077 - val_loss: 8.6232 - val_accuracy: 0.0653\n",
            "Epoch 13/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 5.2605 - accuracy: 0.1147 - val_loss: 9.1649 - val_accuracy: 0.0628\n",
            "Epoch 14/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 5.1630 - accuracy: 0.1232 - val_loss: 9.2154 - val_accuracy: 0.0604\n",
            "Epoch 15/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 5.0619 - accuracy: 0.1281 - val_loss: 9.3672 - val_accuracy: 0.0558\n",
            "Epoch 16/400\n",
            "102/102 [==============================] - 11s 112ms/step - loss: 4.9509 - accuracy: 0.1337 - val_loss: 9.4772 - val_accuracy: 0.0585\n",
            "Epoch 17/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 4.8528 - accuracy: 0.1380 - val_loss: 10.0699 - val_accuracy: 0.0579\n",
            "Epoch 18/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 4.7468 - accuracy: 0.1472 - val_loss: 10.2214 - val_accuracy: 0.0549\n",
            "Epoch 19/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 4.6486 - accuracy: 0.1554 - val_loss: 10.3271 - val_accuracy: 0.0530\n",
            "Epoch 20/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 4.5533 - accuracy: 0.1575 - val_loss: 10.6636 - val_accuracy: 0.0524\n",
            "Epoch 21/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 4.4467 - accuracy: 0.1710 - val_loss: 11.1533 - val_accuracy: 0.0466\n",
            "Epoch 22/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 4.3481 - accuracy: 0.1740 - val_loss: 11.4431 - val_accuracy: 0.0530\n",
            "Epoch 23/400\n",
            "102/102 [==============================] - 10s 103ms/step - loss: 4.2563 - accuracy: 0.1809 - val_loss: 11.5826 - val_accuracy: 0.0533\n",
            "Epoch 24/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 4.1524 - accuracy: 0.1897 - val_loss: 12.2514 - val_accuracy: 0.0484\n",
            "Epoch 25/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 4.0675 - accuracy: 0.1992 - val_loss: 12.7196 - val_accuracy: 0.0438\n",
            "Epoch 26/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 3.9648 - accuracy: 0.2046 - val_loss: 12.8087 - val_accuracy: 0.0435\n",
            "Epoch 27/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 3.8831 - accuracy: 0.2110 - val_loss: 13.0445 - val_accuracy: 0.0475\n",
            "Epoch 28/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 3.8002 - accuracy: 0.2151 - val_loss: 13.6486 - val_accuracy: 0.0496\n",
            "Epoch 29/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 3.6985 - accuracy: 0.2290 - val_loss: 13.5771 - val_accuracy: 0.0435\n",
            "Epoch 30/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 3.6158 - accuracy: 0.2354 - val_loss: 14.3820 - val_accuracy: 0.0454\n",
            "Epoch 31/400\n",
            "102/102 [==============================] - 11s 111ms/step - loss: 3.5377 - accuracy: 0.2448 - val_loss: 14.6958 - val_accuracy: 0.0457\n",
            "Epoch 32/400\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 3.4548 - accuracy: 0.2521 - val_loss: 14.9427 - val_accuracy: 0.0457\n",
            "Epoch 33/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 3.3779 - accuracy: 0.2659 - val_loss: 15.4689 - val_accuracy: 0.0401\n",
            "Epoch 34/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 3.3018 - accuracy: 0.2759 - val_loss: 15.5578 - val_accuracy: 0.0389\n",
            "Epoch 35/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 3.2440 - accuracy: 0.2770 - val_loss: 15.9921 - val_accuracy: 0.0472\n",
            "Epoch 36/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 3.1646 - accuracy: 0.2896 - val_loss: 16.1687 - val_accuracy: 0.0481\n",
            "Epoch 37/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 3.0949 - accuracy: 0.2933 - val_loss: 16.7336 - val_accuracy: 0.0426\n",
            "Epoch 38/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 3.0188 - accuracy: 0.3111 - val_loss: 16.6830 - val_accuracy: 0.0429\n",
            "Epoch 39/400\n",
            "102/102 [==============================] - 11s 108ms/step - loss: 2.9556 - accuracy: 0.3187 - val_loss: 17.5363 - val_accuracy: 0.0432\n",
            "Epoch 40/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 2.8815 - accuracy: 0.3247 - val_loss: 17.1646 - val_accuracy: 0.0481\n",
            "Epoch 41/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 2.8206 - accuracy: 0.3406 - val_loss: 18.0534 - val_accuracy: 0.0466\n",
            "Epoch 42/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 2.7472 - accuracy: 0.3522 - val_loss: 18.0926 - val_accuracy: 0.0438\n",
            "Epoch 43/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 2.6884 - accuracy: 0.3632 - val_loss: 18.3450 - val_accuracy: 0.0447\n",
            "Epoch 44/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 2.6338 - accuracy: 0.3704 - val_loss: 18.4893 - val_accuracy: 0.0420\n",
            "Epoch 45/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 2.5840 - accuracy: 0.3757 - val_loss: 18.9858 - val_accuracy: 0.0457\n",
            "Epoch 46/400\n",
            "102/102 [==============================] - 11s 113ms/step - loss: 2.5291 - accuracy: 0.3900 - val_loss: 19.4961 - val_accuracy: 0.0475\n",
            "Epoch 47/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 2.4726 - accuracy: 0.4005 - val_loss: 19.7144 - val_accuracy: 0.0463\n",
            "Epoch 48/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 2.4217 - accuracy: 0.4116 - val_loss: 20.0556 - val_accuracy: 0.0423\n",
            "Epoch 49/400\n",
            "102/102 [==============================] - 10s 93ms/step - loss: 2.3767 - accuracy: 0.4165 - val_loss: 20.5044 - val_accuracy: 0.0472\n",
            "Epoch 50/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 2.3322 - accuracy: 0.4300 - val_loss: 20.5578 - val_accuracy: 0.0432\n",
            "Epoch 51/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 2.2853 - accuracy: 0.4323 - val_loss: 21.1191 - val_accuracy: 0.0414\n",
            "Epoch 52/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 2.2530 - accuracy: 0.4388 - val_loss: 21.1498 - val_accuracy: 0.0447\n",
            "Epoch 53/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 2.1876 - accuracy: 0.4546 - val_loss: 22.1469 - val_accuracy: 0.0466\n",
            "Epoch 54/400\n",
            "102/102 [==============================] - 11s 107ms/step - loss: 2.1462 - accuracy: 0.4680 - val_loss: 22.2978 - val_accuracy: 0.0472\n",
            "Epoch 55/400\n",
            "102/102 [==============================] - 10s 93ms/step - loss: 2.0900 - accuracy: 0.4772 - val_loss: 22.6945 - val_accuracy: 0.0414\n",
            "Epoch 56/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 2.0649 - accuracy: 0.4800 - val_loss: 22.7263 - val_accuracy: 0.0457\n",
            "Epoch 57/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 2.0187 - accuracy: 0.4885 - val_loss: 22.6115 - val_accuracy: 0.0481\n",
            "Epoch 58/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 2.0025 - accuracy: 0.4966 - val_loss: 23.2748 - val_accuracy: 0.0398\n",
            "Epoch 59/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 1.9515 - accuracy: 0.5060 - val_loss: 23.4715 - val_accuracy: 0.0429\n",
            "Epoch 60/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.8983 - accuracy: 0.5219 - val_loss: 23.8323 - val_accuracy: 0.0447\n",
            "Epoch 61/400\n",
            "102/102 [==============================] - 11s 112ms/step - loss: 1.8959 - accuracy: 0.5198 - val_loss: 23.5649 - val_accuracy: 0.0454\n",
            "Epoch 62/400\n",
            "102/102 [==============================] - 10s 93ms/step - loss: 1.8576 - accuracy: 0.5225 - val_loss: 24.2381 - val_accuracy: 0.0447\n",
            "Epoch 63/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.8043 - accuracy: 0.5320 - val_loss: 24.6526 - val_accuracy: 0.0441\n",
            "Epoch 64/400\n",
            "102/102 [==============================] - 10s 93ms/step - loss: 1.7955 - accuracy: 0.5364 - val_loss: 25.2513 - val_accuracy: 0.0487\n",
            "Epoch 65/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.7796 - accuracy: 0.5433 - val_loss: 25.5701 - val_accuracy: 0.0484\n",
            "Epoch 66/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.7330 - accuracy: 0.5550 - val_loss: 26.2477 - val_accuracy: 0.0432\n",
            "Epoch 67/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.7078 - accuracy: 0.5629 - val_loss: 25.3230 - val_accuracy: 0.0457\n",
            "Epoch 68/400\n",
            "102/102 [==============================] - 10s 101ms/step - loss: 1.6682 - accuracy: 0.5683 - val_loss: 26.8124 - val_accuracy: 0.0451\n",
            "Epoch 69/400\n",
            "102/102 [==============================] - 11s 103ms/step - loss: 1.6635 - accuracy: 0.5676 - val_loss: 26.5523 - val_accuracy: 0.0447\n",
            "Epoch 70/400\n",
            "102/102 [==============================] - 10s 93ms/step - loss: 1.6488 - accuracy: 0.5693 - val_loss: 26.4711 - val_accuracy: 0.0426\n",
            "Epoch 71/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.6098 - accuracy: 0.5806 - val_loss: 27.6824 - val_accuracy: 0.0463\n",
            "Epoch 72/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.6099 - accuracy: 0.5852 - val_loss: 26.6846 - val_accuracy: 0.0463\n",
            "Epoch 73/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.5719 - accuracy: 0.5869 - val_loss: 27.0996 - val_accuracy: 0.0457\n",
            "Epoch 74/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.5366 - accuracy: 0.5951 - val_loss: 28.2661 - val_accuracy: 0.0506\n",
            "Epoch 75/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 1.5118 - accuracy: 0.6021 - val_loss: 27.9922 - val_accuracy: 0.0484\n",
            "Epoch 76/400\n",
            "102/102 [==============================] - 11s 112ms/step - loss: 1.4923 - accuracy: 0.6091 - val_loss: 28.3421 - val_accuracy: 0.0472\n",
            "Epoch 77/400\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 1.4952 - accuracy: 0.6091 - val_loss: 28.0793 - val_accuracy: 0.0487\n",
            "Epoch 78/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.4686 - accuracy: 0.6130 - val_loss: 28.2073 - val_accuracy: 0.0423\n",
            "Epoch 79/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.4676 - accuracy: 0.6087 - val_loss: 28.6687 - val_accuracy: 0.0484\n",
            "Epoch 80/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.4335 - accuracy: 0.6222 - val_loss: 28.5580 - val_accuracy: 0.0460\n",
            "Epoch 81/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.4370 - accuracy: 0.6209 - val_loss: 29.3147 - val_accuracy: 0.0478\n",
            "Epoch 82/400\n",
            "102/102 [==============================] - 10s 93ms/step - loss: 1.4014 - accuracy: 0.6291 - val_loss: 29.4807 - val_accuracy: 0.0487\n",
            "Epoch 83/400\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 1.3941 - accuracy: 0.6297 - val_loss: 29.4150 - val_accuracy: 0.0454\n",
            "Epoch 84/400\n",
            "102/102 [==============================] - 11s 107ms/step - loss: 1.3751 - accuracy: 0.6317 - val_loss: 29.4672 - val_accuracy: 0.0435\n",
            "Epoch 85/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 1.3567 - accuracy: 0.6388 - val_loss: 30.1083 - val_accuracy: 0.0478\n",
            "Epoch 86/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.3522 - accuracy: 0.6375 - val_loss: 30.1921 - val_accuracy: 0.0447\n",
            "Epoch 87/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.3416 - accuracy: 0.6432 - val_loss: 30.1681 - val_accuracy: 0.0457\n",
            "Epoch 88/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.3367 - accuracy: 0.6409 - val_loss: 29.6440 - val_accuracy: 0.0478\n",
            "Epoch 89/400\n",
            "102/102 [==============================] - 10s 93ms/step - loss: 1.2912 - accuracy: 0.6573 - val_loss: 30.7749 - val_accuracy: 0.0457\n",
            "Epoch 90/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.2908 - accuracy: 0.6599 - val_loss: 30.8379 - val_accuracy: 0.0460\n",
            "Epoch 91/400\n",
            "102/102 [==============================] - 12s 114ms/step - loss: 1.2976 - accuracy: 0.6527 - val_loss: 31.1196 - val_accuracy: 0.0438\n",
            "Epoch 92/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.2673 - accuracy: 0.6596 - val_loss: 31.1368 - val_accuracy: 0.0515\n",
            "Epoch 93/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.2511 - accuracy: 0.6620 - val_loss: 31.4508 - val_accuracy: 0.0469\n",
            "Epoch 94/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 1.2354 - accuracy: 0.6722 - val_loss: 32.0491 - val_accuracy: 0.0441\n",
            "Epoch 95/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 1.2484 - accuracy: 0.6651 - val_loss: 32.0562 - val_accuracy: 0.0475\n",
            "Epoch 96/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.2192 - accuracy: 0.6698 - val_loss: 32.1273 - val_accuracy: 0.0466\n",
            "Epoch 97/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 1.2116 - accuracy: 0.6703 - val_loss: 32.8325 - val_accuracy: 0.0463\n",
            "Epoch 98/400\n",
            "102/102 [==============================] - 12s 113ms/step - loss: 1.2197 - accuracy: 0.6672 - val_loss: 32.2930 - val_accuracy: 0.0460\n",
            "Epoch 99/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.2016 - accuracy: 0.6766 - val_loss: 32.2508 - val_accuracy: 0.0429\n",
            "Epoch 100/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.1958 - accuracy: 0.6758 - val_loss: 32.8425 - val_accuracy: 0.0451\n",
            "Epoch 101/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.1898 - accuracy: 0.6755 - val_loss: 32.0458 - val_accuracy: 0.0493\n",
            "Epoch 102/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.1621 - accuracy: 0.6893 - val_loss: 32.7953 - val_accuracy: 0.0469\n",
            "Epoch 103/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.1581 - accuracy: 0.6875 - val_loss: 32.7108 - val_accuracy: 0.0478\n",
            "Epoch 104/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 1.1284 - accuracy: 0.6921 - val_loss: 33.0888 - val_accuracy: 0.0472\n",
            "Epoch 105/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.1448 - accuracy: 0.6918 - val_loss: 33.1855 - val_accuracy: 0.0463\n",
            "Epoch 106/400\n",
            "102/102 [==============================] - 12s 113ms/step - loss: 1.1455 - accuracy: 0.6884 - val_loss: 33.3873 - val_accuracy: 0.0432\n",
            "Epoch 107/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.1447 - accuracy: 0.6889 - val_loss: 33.4810 - val_accuracy: 0.0463\n",
            "Epoch 108/400\n",
            "102/102 [==============================] - 10s 93ms/step - loss: 1.0952 - accuracy: 0.7012 - val_loss: 34.6718 - val_accuracy: 0.0451\n",
            "Epoch 109/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.1036 - accuracy: 0.7002 - val_loss: 34.3300 - val_accuracy: 0.0447\n",
            "Epoch 110/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 1.1038 - accuracy: 0.6960 - val_loss: 34.9057 - val_accuracy: 0.0478\n",
            "Epoch 111/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.1066 - accuracy: 0.6962 - val_loss: 34.3716 - val_accuracy: 0.0490\n",
            "Epoch 112/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.0979 - accuracy: 0.6997 - val_loss: 34.3460 - val_accuracy: 0.0466\n",
            "Epoch 113/400\n",
            "102/102 [==============================] - 11s 112ms/step - loss: 1.0733 - accuracy: 0.7042 - val_loss: 34.6306 - val_accuracy: 0.0447\n",
            "Epoch 114/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.0743 - accuracy: 0.7036 - val_loss: 35.7800 - val_accuracy: 0.0457\n",
            "Epoch 115/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.0831 - accuracy: 0.7032 - val_loss: 35.0837 - val_accuracy: 0.0435\n",
            "Epoch 116/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 1.0669 - accuracy: 0.7096 - val_loss: 34.7380 - val_accuracy: 0.0451\n",
            "Epoch 117/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.0691 - accuracy: 0.7079 - val_loss: 35.3171 - val_accuracy: 0.0447\n",
            "Epoch 118/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.0489 - accuracy: 0.7115 - val_loss: 35.2240 - val_accuracy: 0.0457\n",
            "Epoch 119/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 1.0153 - accuracy: 0.7200 - val_loss: 35.0754 - val_accuracy: 0.0441\n",
            "Epoch 120/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 1.0181 - accuracy: 0.7233 - val_loss: 35.9713 - val_accuracy: 0.0457\n",
            "Epoch 121/400\n",
            "102/102 [==============================] - 11s 107ms/step - loss: 1.0149 - accuracy: 0.7155 - val_loss: 35.8101 - val_accuracy: 0.0478\n",
            "Epoch 122/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 1.0356 - accuracy: 0.7171 - val_loss: 35.0303 - val_accuracy: 0.0451\n",
            "Epoch 123/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.0316 - accuracy: 0.7155 - val_loss: 35.2455 - val_accuracy: 0.0493\n",
            "Epoch 124/400\n",
            "102/102 [==============================] - 10s 93ms/step - loss: 1.0139 - accuracy: 0.7207 - val_loss: 36.3469 - val_accuracy: 0.0475\n",
            "Epoch 125/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.9944 - accuracy: 0.7302 - val_loss: 36.1777 - val_accuracy: 0.0417\n",
            "Epoch 126/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 1.0015 - accuracy: 0.7248 - val_loss: 35.9619 - val_accuracy: 0.0493\n",
            "Epoch 127/400\n",
            "102/102 [==============================] - 9s 93ms/step - loss: 0.9806 - accuracy: 0.7282 - val_loss: 36.9016 - val_accuracy: 0.0444\n",
            "Epoch 128/400\n",
            "102/102 [==============================] - 12s 115ms/step - loss: 0.9809 - accuracy: 0.7269 - val_loss: 37.5057 - val_accuracy: 0.0432\n",
            "Epoch 129/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.9700 - accuracy: 0.7326 - val_loss: 36.9634 - val_accuracy: 0.0472\n",
            "Epoch 130/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.9614 - accuracy: 0.7332 - val_loss: 37.0694 - val_accuracy: 0.0475\n",
            "Epoch 131/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.9632 - accuracy: 0.7318 - val_loss: 38.4642 - val_accuracy: 0.0487\n",
            "Epoch 132/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.9856 - accuracy: 0.7274 - val_loss: 37.3881 - val_accuracy: 0.0466\n",
            "Epoch 133/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.9514 - accuracy: 0.7372 - val_loss: 37.5155 - val_accuracy: 0.0487\n",
            "Epoch 134/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.9357 - accuracy: 0.7425 - val_loss: 38.0676 - val_accuracy: 0.0451\n",
            "Epoch 135/400\n",
            "102/102 [==============================] - 11s 104ms/step - loss: 0.9401 - accuracy: 0.7386 - val_loss: 37.6671 - val_accuracy: 0.0435\n",
            "Epoch 136/400\n",
            "102/102 [==============================] - 10s 101ms/step - loss: 0.9517 - accuracy: 0.7334 - val_loss: 37.8111 - val_accuracy: 0.0466\n",
            "Epoch 137/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.9372 - accuracy: 0.7382 - val_loss: 38.5820 - val_accuracy: 0.0444\n",
            "Epoch 138/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.9533 - accuracy: 0.7329 - val_loss: 37.2376 - val_accuracy: 0.0466\n",
            "Epoch 139/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.9386 - accuracy: 0.7415 - val_loss: 38.0362 - val_accuracy: 0.0490\n",
            "Epoch 140/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.9223 - accuracy: 0.7420 - val_loss: 38.2065 - val_accuracy: 0.0466\n",
            "Epoch 141/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.9071 - accuracy: 0.7492 - val_loss: 38.8326 - val_accuracy: 0.0447\n",
            "Epoch 142/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.9240 - accuracy: 0.7456 - val_loss: 38.7423 - val_accuracy: 0.0484\n",
            "Epoch 143/400\n",
            "102/102 [==============================] - 12s 115ms/step - loss: 0.9002 - accuracy: 0.7503 - val_loss: 38.5955 - val_accuracy: 0.0466\n",
            "Epoch 144/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.9258 - accuracy: 0.7473 - val_loss: 38.4783 - val_accuracy: 0.0487\n",
            "Epoch 145/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.9084 - accuracy: 0.7478 - val_loss: 38.5652 - val_accuracy: 0.0463\n",
            "Epoch 146/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.8822 - accuracy: 0.7534 - val_loss: 39.2610 - val_accuracy: 0.0438\n",
            "Epoch 147/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.8754 - accuracy: 0.7565 - val_loss: 38.9407 - val_accuracy: 0.0438\n",
            "Epoch 148/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.8790 - accuracy: 0.7521 - val_loss: 39.9252 - val_accuracy: 0.0454\n",
            "Epoch 149/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.8860 - accuracy: 0.7519 - val_loss: 39.7593 - val_accuracy: 0.0451\n",
            "Epoch 150/400\n",
            "102/102 [==============================] - 12s 114ms/step - loss: 0.8875 - accuracy: 0.7531 - val_loss: 39.7653 - val_accuracy: 0.0451\n",
            "Epoch 151/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.8877 - accuracy: 0.7502 - val_loss: 38.8817 - val_accuracy: 0.0457\n",
            "Epoch 152/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.8815 - accuracy: 0.7551 - val_loss: 39.4576 - val_accuracy: 0.0438\n",
            "Epoch 153/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.8944 - accuracy: 0.7479 - val_loss: 40.0568 - val_accuracy: 0.0444\n",
            "Epoch 154/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.9009 - accuracy: 0.7460 - val_loss: 40.0243 - val_accuracy: 0.0447\n",
            "Epoch 155/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.8804 - accuracy: 0.7550 - val_loss: 40.0307 - val_accuracy: 0.0457\n",
            "Epoch 156/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.8515 - accuracy: 0.7598 - val_loss: 39.4260 - val_accuracy: 0.0500\n",
            "Epoch 157/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.8646 - accuracy: 0.7561 - val_loss: 39.7659 - val_accuracy: 0.0441\n",
            "Epoch 158/400\n",
            "102/102 [==============================] - 12s 118ms/step - loss: 0.8458 - accuracy: 0.7613 - val_loss: 39.5757 - val_accuracy: 0.0435\n",
            "Epoch 159/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.8473 - accuracy: 0.7662 - val_loss: 39.4834 - val_accuracy: 0.0423\n",
            "Epoch 160/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.8438 - accuracy: 0.7622 - val_loss: 39.5799 - val_accuracy: 0.0463\n",
            "Epoch 161/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.8370 - accuracy: 0.7649 - val_loss: 40.5193 - val_accuracy: 0.0472\n",
            "Epoch 162/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.8442 - accuracy: 0.7649 - val_loss: 39.7437 - val_accuracy: 0.0460\n",
            "Epoch 163/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.8312 - accuracy: 0.7644 - val_loss: 40.2041 - val_accuracy: 0.0426\n",
            "Epoch 164/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.8387 - accuracy: 0.7626 - val_loss: 40.4881 - val_accuracy: 0.0490\n",
            "Epoch 165/400\n",
            "102/102 [==============================] - 12s 117ms/step - loss: 0.8328 - accuracy: 0.7664 - val_loss: 41.4759 - val_accuracy: 0.0481\n",
            "Epoch 166/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.8250 - accuracy: 0.7676 - val_loss: 41.1613 - val_accuracy: 0.0441\n",
            "Epoch 167/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.8184 - accuracy: 0.7708 - val_loss: 41.5137 - val_accuracy: 0.0460\n",
            "Epoch 168/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.8250 - accuracy: 0.7679 - val_loss: 41.3317 - val_accuracy: 0.0417\n",
            "Epoch 169/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.8322 - accuracy: 0.7661 - val_loss: 41.1625 - val_accuracy: 0.0506\n",
            "Epoch 170/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.8248 - accuracy: 0.7693 - val_loss: 41.0925 - val_accuracy: 0.0487\n",
            "Epoch 171/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.8156 - accuracy: 0.7697 - val_loss: 40.6690 - val_accuracy: 0.0487\n",
            "Epoch 172/400\n",
            "102/102 [==============================] - 11s 110ms/step - loss: 0.8098 - accuracy: 0.7705 - val_loss: 42.2222 - val_accuracy: 0.0460\n",
            "Epoch 173/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.7975 - accuracy: 0.7733 - val_loss: 42.1990 - val_accuracy: 0.0457\n",
            "Epoch 174/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7998 - accuracy: 0.7694 - val_loss: 42.5300 - val_accuracy: 0.0472\n",
            "Epoch 175/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.7882 - accuracy: 0.7757 - val_loss: 42.1259 - val_accuracy: 0.0447\n",
            "Epoch 176/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.7770 - accuracy: 0.7798 - val_loss: 41.4596 - val_accuracy: 0.0454\n",
            "Epoch 177/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.7992 - accuracy: 0.7755 - val_loss: 42.0306 - val_accuracy: 0.0398\n",
            "Epoch 178/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.8083 - accuracy: 0.7718 - val_loss: 41.6988 - val_accuracy: 0.0451\n",
            "Epoch 179/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.8026 - accuracy: 0.7711 - val_loss: 42.0000 - val_accuracy: 0.0429\n",
            "Epoch 180/400\n",
            "102/102 [==============================] - 12s 115ms/step - loss: 0.8086 - accuracy: 0.7689 - val_loss: 41.3891 - val_accuracy: 0.0478\n",
            "Epoch 181/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.7944 - accuracy: 0.7746 - val_loss: 41.5687 - val_accuracy: 0.0447\n",
            "Epoch 182/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.7753 - accuracy: 0.7810 - val_loss: 42.1803 - val_accuracy: 0.0417\n",
            "Epoch 183/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7845 - accuracy: 0.7783 - val_loss: 41.2084 - val_accuracy: 0.0447\n",
            "Epoch 184/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.7828 - accuracy: 0.7725 - val_loss: 41.7103 - val_accuracy: 0.0463\n",
            "Epoch 185/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7716 - accuracy: 0.7823 - val_loss: 42.7640 - val_accuracy: 0.0463\n",
            "Epoch 186/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7674 - accuracy: 0.7817 - val_loss: 42.2192 - val_accuracy: 0.0447\n",
            "Epoch 187/400\n",
            "102/102 [==============================] - 11s 113ms/step - loss: 0.7774 - accuracy: 0.7764 - val_loss: 42.5089 - val_accuracy: 0.0423\n",
            "Epoch 188/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7763 - accuracy: 0.7775 - val_loss: 42.8728 - val_accuracy: 0.0472\n",
            "Epoch 189/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.7801 - accuracy: 0.7774 - val_loss: 42.6293 - val_accuracy: 0.0469\n",
            "Epoch 190/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7779 - accuracy: 0.7813 - val_loss: 41.9474 - val_accuracy: 0.0383\n",
            "Epoch 191/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7699 - accuracy: 0.7802 - val_loss: 42.1584 - val_accuracy: 0.0429\n",
            "Epoch 192/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7546 - accuracy: 0.7871 - val_loss: 42.6995 - val_accuracy: 0.0447\n",
            "Epoch 193/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7530 - accuracy: 0.7842 - val_loss: 42.6388 - val_accuracy: 0.0392\n",
            "Epoch 194/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.7503 - accuracy: 0.7824 - val_loss: 42.7015 - val_accuracy: 0.0447\n",
            "Epoch 195/400\n",
            "102/102 [==============================] - 12s 116ms/step - loss: 0.7625 - accuracy: 0.7827 - val_loss: 43.0268 - val_accuracy: 0.0432\n",
            "Epoch 196/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.7459 - accuracy: 0.7882 - val_loss: 43.6625 - val_accuracy: 0.0429\n",
            "Epoch 197/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7386 - accuracy: 0.7872 - val_loss: 43.9411 - val_accuracy: 0.0451\n",
            "Epoch 198/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7344 - accuracy: 0.7915 - val_loss: 43.9184 - val_accuracy: 0.0524\n",
            "Epoch 199/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7619 - accuracy: 0.7843 - val_loss: 43.7952 - val_accuracy: 0.0451\n",
            "Epoch 200/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7400 - accuracy: 0.7924 - val_loss: 42.3266 - val_accuracy: 0.0454\n",
            "Epoch 201/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.7496 - accuracy: 0.7853 - val_loss: 43.3371 - val_accuracy: 0.0460\n",
            "Epoch 202/400\n",
            "102/102 [==============================] - 11s 112ms/step - loss: 0.7527 - accuracy: 0.7880 - val_loss: 43.3737 - val_accuracy: 0.0429\n",
            "Epoch 203/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.7629 - accuracy: 0.7853 - val_loss: 42.9841 - val_accuracy: 0.0472\n",
            "Epoch 204/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.7401 - accuracy: 0.7877 - val_loss: 43.6879 - val_accuracy: 0.0466\n",
            "Epoch 205/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7321 - accuracy: 0.7872 - val_loss: 43.2448 - val_accuracy: 0.0475\n",
            "Epoch 206/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7167 - accuracy: 0.7935 - val_loss: 44.1759 - val_accuracy: 0.0460\n",
            "Epoch 207/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.7352 - accuracy: 0.7875 - val_loss: 42.4962 - val_accuracy: 0.0472\n",
            "Epoch 208/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.7243 - accuracy: 0.7948 - val_loss: 43.5883 - val_accuracy: 0.0475\n",
            "Epoch 209/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.7332 - accuracy: 0.7908 - val_loss: 44.0072 - val_accuracy: 0.0478\n",
            "Epoch 210/400\n",
            "102/102 [==============================] - 12s 113ms/step - loss: 0.7268 - accuracy: 0.7896 - val_loss: 44.0411 - val_accuracy: 0.0460\n",
            "Epoch 211/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7322 - accuracy: 0.7907 - val_loss: 43.6219 - val_accuracy: 0.0457\n",
            "Epoch 212/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7223 - accuracy: 0.7927 - val_loss: 43.8190 - val_accuracy: 0.0484\n",
            "Epoch 213/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.7186 - accuracy: 0.7948 - val_loss: 43.3625 - val_accuracy: 0.0469\n",
            "Epoch 214/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7148 - accuracy: 0.7954 - val_loss: 43.4276 - val_accuracy: 0.0423\n",
            "Epoch 215/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7100 - accuracy: 0.7958 - val_loss: 43.7348 - val_accuracy: 0.0435\n",
            "Epoch 216/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7166 - accuracy: 0.7947 - val_loss: 43.9630 - val_accuracy: 0.0457\n",
            "Epoch 217/400\n",
            "102/102 [==============================] - 11s 111ms/step - loss: 0.7260 - accuracy: 0.7922 - val_loss: 44.0891 - val_accuracy: 0.0484\n",
            "Epoch 218/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.7068 - accuracy: 0.7955 - val_loss: 44.0161 - val_accuracy: 0.0454\n",
            "Epoch 219/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.7048 - accuracy: 0.7951 - val_loss: 44.1738 - val_accuracy: 0.0447\n",
            "Epoch 220/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.7179 - accuracy: 0.7944 - val_loss: 43.3737 - val_accuracy: 0.0444\n",
            "Epoch 221/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.6976 - accuracy: 0.7973 - val_loss: 44.7525 - val_accuracy: 0.0472\n",
            "Epoch 222/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.6941 - accuracy: 0.7998 - val_loss: 43.5214 - val_accuracy: 0.0447\n",
            "Epoch 223/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7149 - accuracy: 0.7980 - val_loss: 44.1875 - val_accuracy: 0.0469\n",
            "Epoch 224/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6852 - accuracy: 0.8004 - val_loss: 45.3600 - val_accuracy: 0.0475\n",
            "Epoch 225/400\n",
            "102/102 [==============================] - 12s 116ms/step - loss: 0.7036 - accuracy: 0.7970 - val_loss: 44.4016 - val_accuracy: 0.0457\n",
            "Epoch 226/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.7065 - accuracy: 0.7954 - val_loss: 44.7965 - val_accuracy: 0.0444\n",
            "Epoch 227/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.7071 - accuracy: 0.7958 - val_loss: 44.3530 - val_accuracy: 0.0512\n",
            "Epoch 228/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6946 - accuracy: 0.7976 - val_loss: 45.0100 - val_accuracy: 0.0463\n",
            "Epoch 229/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6953 - accuracy: 0.7991 - val_loss: 45.5991 - val_accuracy: 0.0454\n",
            "Epoch 230/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6834 - accuracy: 0.8046 - val_loss: 45.0030 - val_accuracy: 0.0447\n",
            "Epoch 231/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6999 - accuracy: 0.7974 - val_loss: 45.3745 - val_accuracy: 0.0457\n",
            "Epoch 232/400\n",
            "102/102 [==============================] - 12s 114ms/step - loss: 0.6834 - accuracy: 0.8032 - val_loss: 45.3754 - val_accuracy: 0.0435\n",
            "Epoch 233/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.6936 - accuracy: 0.7997 - val_loss: 45.0321 - val_accuracy: 0.0441\n",
            "Epoch 234/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.6728 - accuracy: 0.8055 - val_loss: 45.3683 - val_accuracy: 0.0460\n",
            "Epoch 235/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.6692 - accuracy: 0.8063 - val_loss: 46.1464 - val_accuracy: 0.0478\n",
            "Epoch 236/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.6990 - accuracy: 0.7991 - val_loss: 45.0520 - val_accuracy: 0.0454\n",
            "Epoch 237/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6951 - accuracy: 0.7993 - val_loss: 44.9461 - val_accuracy: 0.0487\n",
            "Epoch 238/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.7021 - accuracy: 0.7964 - val_loss: 45.5563 - val_accuracy: 0.0487\n",
            "Epoch 239/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.6881 - accuracy: 0.8003 - val_loss: 45.1569 - val_accuracy: 0.0451\n",
            "Epoch 240/400\n",
            "102/102 [==============================] - 12s 114ms/step - loss: 0.6836 - accuracy: 0.8010 - val_loss: 45.1263 - val_accuracy: 0.0466\n",
            "Epoch 241/400\n",
            "102/102 [==============================] - 10s 94ms/step - loss: 0.6770 - accuracy: 0.8025 - val_loss: 45.7225 - val_accuracy: 0.0444\n",
            "Epoch 242/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.6645 - accuracy: 0.8087 - val_loss: 45.4115 - val_accuracy: 0.0414\n",
            "Epoch 243/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6606 - accuracy: 0.8094 - val_loss: 45.9657 - val_accuracy: 0.0457\n",
            "Epoch 244/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6687 - accuracy: 0.8017 - val_loss: 45.9166 - val_accuracy: 0.0469\n",
            "Epoch 245/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6737 - accuracy: 0.8039 - val_loss: 45.5785 - val_accuracy: 0.0411\n",
            "Epoch 246/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6669 - accuracy: 0.8073 - val_loss: 45.6315 - val_accuracy: 0.0447\n",
            "Epoch 247/400\n",
            "102/102 [==============================] - 11s 112ms/step - loss: 0.6624 - accuracy: 0.8070 - val_loss: 45.9056 - val_accuracy: 0.0484\n",
            "Epoch 248/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6840 - accuracy: 0.8020 - val_loss: 45.6399 - val_accuracy: 0.0500\n",
            "Epoch 249/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6912 - accuracy: 0.7997 - val_loss: 45.2983 - val_accuracy: 0.0444\n",
            "Epoch 250/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6686 - accuracy: 0.8041 - val_loss: 46.4755 - val_accuracy: 0.0500\n",
            "Epoch 251/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6763 - accuracy: 0.8020 - val_loss: 46.4560 - val_accuracy: 0.0429\n",
            "Epoch 252/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6665 - accuracy: 0.8041 - val_loss: 45.8835 - val_accuracy: 0.0472\n",
            "Epoch 253/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6718 - accuracy: 0.8069 - val_loss: 46.1313 - val_accuracy: 0.0444\n",
            "Epoch 254/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6650 - accuracy: 0.8058 - val_loss: 45.7541 - val_accuracy: 0.0432\n",
            "Epoch 255/400\n",
            "102/102 [==============================] - 12s 118ms/step - loss: 0.6555 - accuracy: 0.8111 - val_loss: 45.3002 - val_accuracy: 0.0429\n",
            "Epoch 256/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6488 - accuracy: 0.8087 - val_loss: 46.5956 - val_accuracy: 0.0454\n",
            "Epoch 257/400\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 0.6443 - accuracy: 0.8108 - val_loss: 46.4794 - val_accuracy: 0.0454\n",
            "Epoch 258/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6475 - accuracy: 0.8125 - val_loss: 46.5981 - val_accuracy: 0.0481\n",
            "Epoch 259/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6465 - accuracy: 0.8125 - val_loss: 47.8568 - val_accuracy: 0.0481\n",
            "Epoch 260/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6423 - accuracy: 0.8139 - val_loss: 46.6213 - val_accuracy: 0.0466\n",
            "Epoch 261/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6482 - accuracy: 0.8090 - val_loss: 46.6966 - val_accuracy: 0.0451\n",
            "Epoch 262/400\n",
            "102/102 [==============================] - 12s 115ms/step - loss: 0.6582 - accuracy: 0.8056 - val_loss: 46.5684 - val_accuracy: 0.0451\n",
            "Epoch 263/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6438 - accuracy: 0.8114 - val_loss: 47.0250 - val_accuracy: 0.0460\n",
            "Epoch 264/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6627 - accuracy: 0.8086 - val_loss: 47.4358 - val_accuracy: 0.0444\n",
            "Epoch 265/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6394 - accuracy: 0.8132 - val_loss: 46.9322 - val_accuracy: 0.0487\n",
            "Epoch 266/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6548 - accuracy: 0.8066 - val_loss: 46.6440 - val_accuracy: 0.0481\n",
            "Epoch 267/400\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 0.6536 - accuracy: 0.8096 - val_loss: 46.2503 - val_accuracy: 0.0441\n",
            "Epoch 268/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6395 - accuracy: 0.8117 - val_loss: 46.6163 - val_accuracy: 0.0478\n",
            "Epoch 269/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6608 - accuracy: 0.8065 - val_loss: 46.5293 - val_accuracy: 0.0506\n",
            "Epoch 270/400\n",
            "102/102 [==============================] - 12s 117ms/step - loss: 0.6626 - accuracy: 0.8069 - val_loss: 44.8929 - val_accuracy: 0.0469\n",
            "Epoch 271/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6654 - accuracy: 0.8053 - val_loss: 45.4082 - val_accuracy: 0.0466\n",
            "Epoch 272/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6485 - accuracy: 0.8118 - val_loss: 47.0727 - val_accuracy: 0.0447\n",
            "Epoch 273/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6501 - accuracy: 0.8096 - val_loss: 45.6392 - val_accuracy: 0.0481\n",
            "Epoch 274/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6403 - accuracy: 0.8138 - val_loss: 46.8974 - val_accuracy: 0.0487\n",
            "Epoch 275/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6334 - accuracy: 0.8151 - val_loss: 47.8737 - val_accuracy: 0.0490\n",
            "Epoch 276/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6302 - accuracy: 0.8138 - val_loss: 47.1449 - val_accuracy: 0.0466\n",
            "Epoch 277/400\n",
            "102/102 [==============================] - 12s 118ms/step - loss: 0.6289 - accuracy: 0.8187 - val_loss: 47.5994 - val_accuracy: 0.0490\n",
            "Epoch 278/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6436 - accuracy: 0.8122 - val_loss: 47.6395 - val_accuracy: 0.0457\n",
            "Epoch 279/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6491 - accuracy: 0.8114 - val_loss: 46.2567 - val_accuracy: 0.0481\n",
            "Epoch 280/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6297 - accuracy: 0.8168 - val_loss: 47.5976 - val_accuracy: 0.0463\n",
            "Epoch 281/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6241 - accuracy: 0.8138 - val_loss: 47.8539 - val_accuracy: 0.0481\n",
            "Epoch 282/400\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 0.6318 - accuracy: 0.8148 - val_loss: 47.1978 - val_accuracy: 0.0484\n",
            "Epoch 283/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6247 - accuracy: 0.8183 - val_loss: 47.7735 - val_accuracy: 0.0460\n",
            "Epoch 284/400\n",
            "102/102 [==============================] - 11s 110ms/step - loss: 0.6535 - accuracy: 0.8086 - val_loss: 46.3007 - val_accuracy: 0.0490\n",
            "Epoch 285/400\n",
            "102/102 [==============================] - 11s 105ms/step - loss: 0.6369 - accuracy: 0.8122 - val_loss: 46.6480 - val_accuracy: 0.0472\n",
            "Epoch 286/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6319 - accuracy: 0.8160 - val_loss: 47.8100 - val_accuracy: 0.0478\n",
            "Epoch 287/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6241 - accuracy: 0.8168 - val_loss: 47.2529 - val_accuracy: 0.0441\n",
            "Epoch 288/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6147 - accuracy: 0.8213 - val_loss: 47.9253 - val_accuracy: 0.0457\n",
            "Epoch 289/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6250 - accuracy: 0.8176 - val_loss: 48.3349 - val_accuracy: 0.0454\n",
            "Epoch 290/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6247 - accuracy: 0.8161 - val_loss: 47.0714 - val_accuracy: 0.0451\n",
            "Epoch 291/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6183 - accuracy: 0.8197 - val_loss: 47.9714 - val_accuracy: 0.0469\n",
            "Epoch 292/400\n",
            "102/102 [==============================] - 12s 116ms/step - loss: 0.6371 - accuracy: 0.8127 - val_loss: 47.8771 - val_accuracy: 0.0463\n",
            "Epoch 293/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6416 - accuracy: 0.8132 - val_loss: 46.5837 - val_accuracy: 0.0451\n",
            "Epoch 294/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6319 - accuracy: 0.8158 - val_loss: 48.4869 - val_accuracy: 0.0447\n",
            "Epoch 295/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6245 - accuracy: 0.8174 - val_loss: 47.0035 - val_accuracy: 0.0460\n",
            "Epoch 296/400\n",
            "102/102 [==============================] - 10s 102ms/step - loss: 0.6192 - accuracy: 0.8162 - val_loss: 48.2316 - val_accuracy: 0.0457\n",
            "Epoch 297/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6287 - accuracy: 0.8139 - val_loss: 46.8168 - val_accuracy: 0.0435\n",
            "Epoch 298/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6133 - accuracy: 0.8197 - val_loss: 47.2836 - val_accuracy: 0.0469\n",
            "Epoch 299/400\n",
            "102/102 [==============================] - 12s 117ms/step - loss: 0.6072 - accuracy: 0.8205 - val_loss: 48.8519 - val_accuracy: 0.0444\n",
            "Epoch 300/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6035 - accuracy: 0.8220 - val_loss: 48.8517 - val_accuracy: 0.0451\n",
            "Epoch 301/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6216 - accuracy: 0.8177 - val_loss: 48.5864 - val_accuracy: 0.0481\n",
            "Epoch 302/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6188 - accuracy: 0.8196 - val_loss: 48.3893 - val_accuracy: 0.0451\n",
            "Epoch 303/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6145 - accuracy: 0.8163 - val_loss: 48.8166 - val_accuracy: 0.0481\n",
            "Epoch 304/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6150 - accuracy: 0.8177 - val_loss: 48.2022 - val_accuracy: 0.0469\n",
            "Epoch 305/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6156 - accuracy: 0.8197 - val_loss: 48.2702 - val_accuracy: 0.0493\n",
            "Epoch 306/400\n",
            "102/102 [==============================] - 10s 103ms/step - loss: 0.6078 - accuracy: 0.8202 - val_loss: 48.6839 - val_accuracy: 0.0500\n",
            "Epoch 307/400\n",
            "102/102 [==============================] - 11s 111ms/step - loss: 0.6114 - accuracy: 0.8194 - val_loss: 48.5667 - val_accuracy: 0.0487\n",
            "Epoch 308/400\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 0.6066 - accuracy: 0.8210 - val_loss: 48.1997 - val_accuracy: 0.0472\n",
            "Epoch 309/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6138 - accuracy: 0.8211 - val_loss: 48.8520 - val_accuracy: 0.0460\n",
            "Epoch 310/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6157 - accuracy: 0.8185 - val_loss: 47.8693 - val_accuracy: 0.0457\n",
            "Epoch 311/400\n",
            "102/102 [==============================] - 10s 96ms/step - loss: 0.6047 - accuracy: 0.8208 - val_loss: 49.0835 - val_accuracy: 0.0472\n",
            "Epoch 312/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6050 - accuracy: 0.8210 - val_loss: 49.5599 - val_accuracy: 0.0460\n",
            "Epoch 313/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6065 - accuracy: 0.8203 - val_loss: 48.4983 - val_accuracy: 0.0457\n",
            "Epoch 314/400\n",
            "102/102 [==============================] - 12s 118ms/step - loss: 0.6052 - accuracy: 0.8178 - val_loss: 47.9454 - val_accuracy: 0.0466\n",
            "Epoch 315/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.5977 - accuracy: 0.8237 - val_loss: 49.5328 - val_accuracy: 0.0472\n",
            "Epoch 316/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6186 - accuracy: 0.8154 - val_loss: 48.3855 - val_accuracy: 0.0493\n",
            "Epoch 317/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.6086 - accuracy: 0.8189 - val_loss: 49.5582 - val_accuracy: 0.0454\n",
            "Epoch 318/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6288 - accuracy: 0.8118 - val_loss: 47.6068 - val_accuracy: 0.0469\n",
            "Epoch 319/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6146 - accuracy: 0.8191 - val_loss: 47.7850 - val_accuracy: 0.0457\n",
            "Epoch 320/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6067 - accuracy: 0.8207 - val_loss: 48.0918 - val_accuracy: 0.0463\n",
            "Epoch 321/400\n",
            "102/102 [==============================] - 12s 117ms/step - loss: 0.6286 - accuracy: 0.8160 - val_loss: 47.7117 - val_accuracy: 0.0451\n",
            "Epoch 322/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6097 - accuracy: 0.8216 - val_loss: 48.1700 - val_accuracy: 0.0487\n",
            "Epoch 323/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.5917 - accuracy: 0.8250 - val_loss: 48.2962 - val_accuracy: 0.0444\n",
            "Epoch 324/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6011 - accuracy: 0.8230 - val_loss: 49.2979 - val_accuracy: 0.0463\n",
            "Epoch 325/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6099 - accuracy: 0.8210 - val_loss: 48.6220 - val_accuracy: 0.0460\n",
            "Epoch 326/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6068 - accuracy: 0.8213 - val_loss: 49.2610 - val_accuracy: 0.0447\n",
            "Epoch 327/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6052 - accuracy: 0.8210 - val_loss: 48.4840 - val_accuracy: 0.0481\n",
            "Epoch 328/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5805 - accuracy: 0.8276 - val_loss: 50.1300 - val_accuracy: 0.0475\n",
            "Epoch 329/400\n",
            "102/102 [==============================] - 12s 116ms/step - loss: 0.5807 - accuracy: 0.8259 - val_loss: 48.3472 - val_accuracy: 0.0475\n",
            "Epoch 330/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.5863 - accuracy: 0.8243 - val_loss: 49.8576 - val_accuracy: 0.0472\n",
            "Epoch 331/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5958 - accuracy: 0.8234 - val_loss: 48.5486 - val_accuracy: 0.0481\n",
            "Epoch 332/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5921 - accuracy: 0.8239 - val_loss: 49.7301 - val_accuracy: 0.0506\n",
            "Epoch 333/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6101 - accuracy: 0.8190 - val_loss: 47.9814 - val_accuracy: 0.0478\n",
            "Epoch 334/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.6146 - accuracy: 0.8155 - val_loss: 49.7014 - val_accuracy: 0.0490\n",
            "Epoch 335/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5959 - accuracy: 0.8240 - val_loss: 49.2688 - val_accuracy: 0.0472\n",
            "Epoch 336/400\n",
            "102/102 [==============================] - 12s 117ms/step - loss: 0.6070 - accuracy: 0.8228 - val_loss: 47.9574 - val_accuracy: 0.0493\n",
            "Epoch 337/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5937 - accuracy: 0.8247 - val_loss: 49.8399 - val_accuracy: 0.0451\n",
            "Epoch 338/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5869 - accuracy: 0.8238 - val_loss: 49.7143 - val_accuracy: 0.0481\n",
            "Epoch 339/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5912 - accuracy: 0.8258 - val_loss: 49.9142 - val_accuracy: 0.0490\n",
            "Epoch 340/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5877 - accuracy: 0.8238 - val_loss: 49.6295 - val_accuracy: 0.0490\n",
            "Epoch 341/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5954 - accuracy: 0.8230 - val_loss: 48.8158 - val_accuracy: 0.0451\n",
            "Epoch 342/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5861 - accuracy: 0.8267 - val_loss: 49.6220 - val_accuracy: 0.0490\n",
            "Epoch 343/400\n",
            "102/102 [==============================] - 12s 115ms/step - loss: 0.5828 - accuracy: 0.8271 - val_loss: 49.6499 - val_accuracy: 0.0496\n",
            "Epoch 344/400\n",
            "102/102 [==============================] - 10s 101ms/step - loss: 0.5744 - accuracy: 0.8297 - val_loss: 49.4878 - val_accuracy: 0.0481\n",
            "Epoch 345/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5838 - accuracy: 0.8250 - val_loss: 49.9756 - val_accuracy: 0.0466\n",
            "Epoch 346/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5840 - accuracy: 0.8286 - val_loss: 49.6180 - val_accuracy: 0.0469\n",
            "Epoch 347/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5784 - accuracy: 0.8254 - val_loss: 48.8844 - val_accuracy: 0.0469\n",
            "Epoch 348/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.6027 - accuracy: 0.8211 - val_loss: 49.3694 - val_accuracy: 0.0454\n",
            "Epoch 349/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5960 - accuracy: 0.8233 - val_loss: 48.4959 - val_accuracy: 0.0463\n",
            "Epoch 350/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5962 - accuracy: 0.8256 - val_loss: 50.2277 - val_accuracy: 0.0457\n",
            "Epoch 351/400\n",
            "102/102 [==============================] - 12s 118ms/step - loss: 0.5846 - accuracy: 0.8275 - val_loss: 49.6794 - val_accuracy: 0.0475\n",
            "Epoch 352/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.5927 - accuracy: 0.8257 - val_loss: 50.1306 - val_accuracy: 0.0475\n",
            "Epoch 353/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.5922 - accuracy: 0.8231 - val_loss: 49.8362 - val_accuracy: 0.0423\n",
            "Epoch 354/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5921 - accuracy: 0.8239 - val_loss: 50.7830 - val_accuracy: 0.0500\n",
            "Epoch 355/400\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 0.5864 - accuracy: 0.8223 - val_loss: 49.7137 - val_accuracy: 0.0481\n",
            "Epoch 356/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.5888 - accuracy: 0.8258 - val_loss: 50.0690 - val_accuracy: 0.0509\n",
            "Epoch 357/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5855 - accuracy: 0.8228 - val_loss: 50.4376 - val_accuracy: 0.0493\n",
            "Epoch 358/400\n",
            "102/102 [==============================] - 12s 116ms/step - loss: 0.5917 - accuracy: 0.8243 - val_loss: 49.1817 - val_accuracy: 0.0496\n",
            "Epoch 359/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5872 - accuracy: 0.8260 - val_loss: 49.6558 - val_accuracy: 0.0493\n",
            "Epoch 360/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5806 - accuracy: 0.8281 - val_loss: 48.5207 - val_accuracy: 0.0481\n",
            "Epoch 361/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5594 - accuracy: 0.8312 - val_loss: 49.7816 - val_accuracy: 0.0475\n",
            "Epoch 362/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5756 - accuracy: 0.8277 - val_loss: 49.9051 - val_accuracy: 0.0466\n",
            "Epoch 363/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.5758 - accuracy: 0.8285 - val_loss: 49.9100 - val_accuracy: 0.0451\n",
            "Epoch 364/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.5647 - accuracy: 0.8309 - val_loss: 51.3410 - val_accuracy: 0.0463\n",
            "Epoch 365/400\n",
            "102/102 [==============================] - 10s 97ms/step - loss: 0.5824 - accuracy: 0.8269 - val_loss: 50.2017 - val_accuracy: 0.0469\n",
            "Epoch 366/400\n",
            "102/102 [==============================] - 12s 117ms/step - loss: 0.5880 - accuracy: 0.8227 - val_loss: 50.3009 - val_accuracy: 0.0478\n",
            "Epoch 367/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5882 - accuracy: 0.8243 - val_loss: 50.2720 - val_accuracy: 0.0472\n",
            "Epoch 368/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5928 - accuracy: 0.8234 - val_loss: 49.5149 - val_accuracy: 0.0481\n",
            "Epoch 369/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5833 - accuracy: 0.8269 - val_loss: 50.7066 - val_accuracy: 0.0487\n",
            "Epoch 370/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5884 - accuracy: 0.8229 - val_loss: 50.4690 - val_accuracy: 0.0472\n",
            "Epoch 371/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5785 - accuracy: 0.8263 - val_loss: 49.9477 - val_accuracy: 0.0493\n",
            "Epoch 372/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5706 - accuracy: 0.8289 - val_loss: 50.9399 - val_accuracy: 0.0496\n",
            "Epoch 373/400\n",
            "102/102 [==============================] - 12s 119ms/step - loss: 0.5847 - accuracy: 0.8272 - val_loss: 50.0576 - val_accuracy: 0.0509\n",
            "Epoch 374/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5839 - accuracy: 0.8270 - val_loss: 50.8384 - val_accuracy: 0.0475\n",
            "Epoch 375/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5812 - accuracy: 0.8266 - val_loss: 50.8069 - val_accuracy: 0.0509\n",
            "Epoch 376/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5725 - accuracy: 0.8286 - val_loss: 51.3444 - val_accuracy: 0.0515\n",
            "Epoch 377/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5784 - accuracy: 0.8293 - val_loss: 50.5320 - val_accuracy: 0.0527\n",
            "Epoch 378/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5636 - accuracy: 0.8315 - val_loss: 49.6220 - val_accuracy: 0.0506\n",
            "Epoch 379/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5637 - accuracy: 0.8295 - val_loss: 52.3575 - val_accuracy: 0.0524\n",
            "Epoch 380/400\n",
            "102/102 [==============================] - 10s 98ms/step - loss: 0.5700 - accuracy: 0.8302 - val_loss: 50.0319 - val_accuracy: 0.0493\n",
            "Epoch 381/400\n",
            "102/102 [==============================] - 12s 118ms/step - loss: 0.5567 - accuracy: 0.8334 - val_loss: 51.4397 - val_accuracy: 0.0533\n",
            "Epoch 382/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5764 - accuracy: 0.8269 - val_loss: 50.7549 - val_accuracy: 0.0512\n",
            "Epoch 383/400\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 0.5785 - accuracy: 0.8290 - val_loss: 51.4106 - val_accuracy: 0.0496\n",
            "Epoch 384/400\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 0.5657 - accuracy: 0.8283 - val_loss: 49.6259 - val_accuracy: 0.0487\n",
            "Epoch 385/400\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 0.5721 - accuracy: 0.8273 - val_loss: 50.7324 - val_accuracy: 0.0487\n",
            "Epoch 386/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5730 - accuracy: 0.8292 - val_loss: 50.5344 - val_accuracy: 0.0506\n",
            "Epoch 387/400\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 0.5587 - accuracy: 0.8321 - val_loss: 50.4227 - val_accuracy: 0.0481\n",
            "Epoch 388/400\n",
            "102/102 [==============================] - 12s 114ms/step - loss: 0.5525 - accuracy: 0.8334 - val_loss: 50.8304 - val_accuracy: 0.0478\n",
            "Epoch 389/400\n",
            "102/102 [==============================] - 10s 101ms/step - loss: 0.5668 - accuracy: 0.8280 - val_loss: 52.4356 - val_accuracy: 0.0469\n",
            "Epoch 390/400\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 0.5721 - accuracy: 0.8292 - val_loss: 50.7835 - val_accuracy: 0.0490\n",
            "Epoch 391/400\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 0.5704 - accuracy: 0.8273 - val_loss: 51.7103 - val_accuracy: 0.0493\n",
            "Epoch 392/400\n",
            "102/102 [==============================] - 10s 101ms/step - loss: 0.5672 - accuracy: 0.8308 - val_loss: 51.4808 - val_accuracy: 0.0493\n",
            "Epoch 393/400\n",
            "102/102 [==============================] - 11s 105ms/step - loss: 0.5725 - accuracy: 0.8322 - val_loss: 50.2785 - val_accuracy: 0.0475\n",
            "Epoch 394/400\n",
            "102/102 [==============================] - 11s 104ms/step - loss: 0.5703 - accuracy: 0.8304 - val_loss: 50.6813 - val_accuracy: 0.0472\n",
            "Epoch 395/400\n",
            "102/102 [==============================] - 10s 102ms/step - loss: 0.5737 - accuracy: 0.8285 - val_loss: 49.6764 - val_accuracy: 0.0484\n",
            "Epoch 396/400\n",
            "102/102 [==============================] - 13s 124ms/step - loss: 0.5821 - accuracy: 0.8256 - val_loss: 50.9220 - val_accuracy: 0.0521\n",
            "Epoch 397/400\n",
            "102/102 [==============================] - 10s 103ms/step - loss: 0.5806 - accuracy: 0.8266 - val_loss: 49.4718 - val_accuracy: 0.0512\n",
            "Epoch 398/400\n",
            "102/102 [==============================] - 11s 104ms/step - loss: 0.5677 - accuracy: 0.8282 - val_loss: 50.4006 - val_accuracy: 0.0503\n",
            "Epoch 399/400\n",
            "102/102 [==============================] - 11s 104ms/step - loss: 0.5576 - accuracy: 0.8309 - val_loss: 50.6181 - val_accuracy: 0.0496\n",
            "Epoch 400/400\n",
            "102/102 [==============================] - 11s 106ms/step - loss: 0.5597 - accuracy: 0.8316 - val_loss: 51.5126 - val_accuracy: 0.0487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-I76kDbhhIN",
        "outputId": "f3e3e4f2-c1b9-4e77-d019-45ce19df3ff3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "model.save('model4.h5')"
      ],
      "metadata": {
        "id": "XV8u3MEazbvP"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}